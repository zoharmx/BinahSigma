Binah-Ïƒ Mvp â€“ Backend & Frontend
Â· other
# BINAH-Î£ MVP


## 1. BACKEND â€“ FastAPI Endpoint


### stack
- Python 3.10+
- FastAPI
- Uvicorn
- OpenAI SDK (o proveedor LLM equivalente)


### estructura mÃ­nima
```
binah_sigma_api/
â”œâ”€ main.py
â”œâ”€ schemas.py
â”œâ”€ engine.py
â”œâ”€ requirements.txt
```


---


### requirements.txt
```
fastapi
uvicorn
pydantic
python-dotenv
openai
```


---


### schemas.py
```python
from pydantic import BaseModel
from typing import List


class BinahSigmaRequest(BaseModel):
    context: str
    decision_question: str
    stakeholders: List[str]
    constraints: List[str]
    time_horizon: str


class BinahSigmaResponse(BaseModel):
    binah_sigma_index: float
    binah_sigma_confidence: float
    decision_coherence: str
    ethical_alignment: str
    systemic_risk: str
    key_tensions: List[str]
    unintended_consequences: List[str]
    binah_recommendation: str
    explanation_summary: str
    analysis_version: str
```


---


### engine.py
```python
from openai import OpenAI
import os


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


BINAH_SIGMA_SYSTEM = """
You are Binah-Î£, a deep synthesis reasoning engine.
Your role is NOT to chat, speculate, persuade, or generate generic advice.


STRICT RULES:

Excelente elecciÃ³n.
Lo que estÃ¡s pidiendo ahora es pasar de â€œbackend correctoâ€ a â€œbackend auditable y profesionalâ€. Voy por partes y con total claridad.
(Nota: intentÃ© aplicar los cambios directamente en el canvas, pero fallÃ³ el match automÃ¡tico del patrÃ³n. Te dejo el cÃ³digo limpio y exacto para que lo pegues sin ambigÃ¼edad).

1ï¸âƒ£ ValidaciÃ³n estricta con Pydantic (anti-respuestas rotas)
Objetivo real

Que NINGÃšN output del modelo llegue al cliente si:

falta un campo

un tipo es incorrecto

el JSON es semÃ¡nticamente invÃ¡lido

El LLM no decide si el anÃ¡lisis es vÃ¡lido.
Lo decide el schema.

ImplementaciÃ³n correcta en engine.py
Imports (clave)
import json
import os
import logging
from pydantic import ValidationError
from openai import AsyncOpenAI
from schemas import BinahSigmaResponse

Logger estructurado (mÃ­nimo pero serio)
logger = logging.getLogger("binah_sigma")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

Engine endurecido + validaciÃ³n estricta
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def run_binah_sigma(data: dict) -> dict:
    prompt = BINAH_SIGMA_PROMPT.format(**data)

    try:
        response = await client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": BINAH_SIGMA_SYSTEM},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"},
            timeout=30
        )

        raw_content = response.choices[0].message.content
        parsed = json.loads(raw_content)

        # ðŸ” VALIDACIÃ“N CRÃTICA
        validated = BinahSigmaResponse(**parsed)

        logger.info(
            "BINAH-Î£ OK | index=%.2f | confidence=%.2f",
            validated.binah_sigma_index,
            validated.binah_sigma_confidence
        )

        return validated.dict()

    except ValidationError as ve:
        logger.error(
            "BINAH-Î£ SCHEMA VIOLATION",
            extra={"errors": ve.errors(), "raw": parsed}
        )
        raise

    except Exception as e:
        logger.exception("BINAH-Î£ ENGINE FAILURE")
        raise





engine.py (VersiÃ³n Segura)
Python

import json
import os
from openai import AsyncOpenAI  # Usamos cliente asÃ­ncrono

# InicializaciÃ³n asÃ­ncrona
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BINAH_SIGMA_SYSTEM = """
You are Binah-Î£, a deep synthesis reasoning engine.
Your role is NOT to chat, speculate, persuade, or generate generic advice.
... (Resto de tu prompt igual) ...
OUTPUT REQUIREMENTS:
- You must output ONLY valid JSON.
"""

BINAH_SIGMA_PROMPT = """
Context: {context}
Decision Question: {decision_question}
Stakeholders: {stakeholders}
Constraints: {constraints}
Time Horizon: {time_horizon}
... (Resto de tu prompt igual) ...
"""

async def run_binah_sigma(data: dict) -> dict:
    prompt = BINAH_SIGMA_PROMPT.format(**data)

    try:
        response = await client.chat.completions.create(
            model="gpt-4-turbo",  # GPT-4 Turbo soporta JSON mode nativo mejor
            messages=[
                {"role": "system", "content": BINAH_SIGMA_SYSTEM},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}  # âš ï¸ FUERZA JSON SEGURO
        )
        
        content = response.choices[0].message.content
        
        # Parseo seguro. Si falla, no rompe el servidor, lanza error controlado.
        return json.loads(content) 
        
    except Exception as e:
        # Manejo de error elegante para devolver un JSON de error
        return {
            "binah_sigma_index": 0.0,
            "decision_coherence": "Error",
            "explanation_summary": f"System Failure: {str(e)}",
            "binah_sigma_confidence": 0.0,
            "key_tensions": [],
            "unintended_consequences": [],
            "ethical_alignment": "N/A",
            "systemic_risk": "N/A",
            "binah_recommendation": "Retry analysis.",
            "analysis_version": "v1.0"
        }









# BINAH-Î£ MVP



## 1. BACKEND â€“ FastAPI Endpoint



### stack

- Python 3.10+

- FastAPI

- Uvicorn

- OpenAI SDK (o proveedor LLM equivalente)



### estructura mÃ­nima

```

binah_sigma_api/

â”œâ”€ main.py

â”œâ”€ schemas.py

â”œâ”€ engine.py

â”œâ”€ requirements.txt

```



---



### requirements.txt

```

fastapi

uvicorn

pydantic

python-dotenv

openai

```



---



### schemas.py

```python

from pydantic import BaseModel

from typing import List



class BinahSigmaRequest(BaseModel):

context: str

decision_question: str

stakeholders: List[str]

constraints: List[str]

time_horizon: str



class BinahSigmaResponse(BaseModel):

binah_sigma_index: float

binah_sigma_confidence: float

decision_coherence: str

ethical_alignment: str

systemic_risk: str

key_tensions: List[str]

unintended_consequences: List[str]

binah_recommendation: str

explanation_summary: str

analysis_version: str

```



---



### engine.py

```python

from openai import OpenAI

import os



client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))



BINAH_SIGMA_SYSTEM = """

You are Binah-Î£, a deep synthesis reasoning engine.

Your role is NOT to chat, speculate, persuade, or generate generic advice.





1ï¸âƒ£ ValidaciÃ³n estricta con Pydantic (anti-respuestas rotas)

Objetivo real

Que NINGÃšN output del modelo llegue al cliente si:



falta un campo

un tipo es incorrecto

el JSON es semÃ¡nticamente invÃ¡lido

El LLM no decide si el anÃ¡lisis es vÃ¡lido.



Lo decide el schema.

ImplementaciÃ³n correcta en engine.py

Imports (clave)



import jsonimport osimport loggingfrom pydantic import ValidationErrorfrom openai import AsyncOpenAIfrom schemas import BinahSigmaResponse

Logger estructurado (mÃ­nimo pero serio)



logger = logging.getLogger("binah_sigma")

logging.basicConfig(

level=logging.INFO,

format="%(asctime)s | %(levelname)s | %(message)s"

)

Engine endurecido + validaciÃ³n estricta



client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))async def run_binah_sigma(data: dict) -> dict:

prompt = BINAH_SIGMA_PROMPT.format(**data)



try:

response = await client.chat.completions.create(

model="gpt-4-turbo",

messages=[

{"role": "system", "content": BINAH_SIGMA_SYSTEM},

{"role": "user", "content": prompt}

],

temperature=0.2,

response_format={"type": "json_object"},

timeout=30

)



raw_content = response.choices[0].message.content

parsed = json.loads(raw_content)



# ðŸ” VALIDACIÃ“N CRÃTICA

validated = BinahSigmaResponse(**parsed)



logger.info(

"BINAH-Î£ OK | index=%.2f | confidence=%.2f",

validated.binah_sigma_index,

validated.binah_sigma_confidence

)



return validated.dict()



except ValidationError as ve:

logger.error(

"BINAH-Î£ SCHEMA VIOLATION",

extra={"errors": ve.errors(), "raw": parsed}

)

raise



except Exception as e:

logger.exception("BINAH-Î£ ENGINE FAILURE")

raise




from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware # Necesario para que el HTML funcione
from schemas import BinahSigmaRequest, BinahSigmaResponse
from engine import run_binah_sigma

app = FastAPI(title="Binah-Î£ Decision Engine")

# Configurar CORS para permitir que tu index.html local llame a la API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/binah-sigma/analyze", response_model=BinahSigmaResponse)
async def analyze_decision(payload: BinahSigmaRequest): # Nota el 'async'
    result = await run_binah_sigma(payload.dict()) # Nota el 'await'
    return result







Binah-Î£

Infraestructura Cognitiva para la EvaluaciÃ³n Ã‰tica y SistÃ©mica de Decisiones

1. Resumen Ejecutivo

Binah-Î£ es una infraestructura cognitiva diseÃ±ada para evaluar decisiones complejas bajo criterios de coherencia sistÃ©mica, alineaciÃ³n Ã©tica y riesgo estructural. A diferencia de los sistemas de IA generativa tradicionales â€”centrados en producir textoâ€” Binah-Î£ opera como un motor de evaluaciÃ³n, entregando salidas estructuradas, medibles y auditables.

El sistema nace de una premisa simple pero poderosa:

El verdadero valor de la inteligencia artificial en contextos crÃ­ticos no es generar respuestas, sino evaluar la calidad de las decisiones.

Binah-Î£ traduce esta premisa en un producto tecnolÃ³gico escalable, orientado a empresas, gobiernos, instituciones financieras, organizaciones multilaterales y sectores regulados.

2. El Problema

Las organizaciones modernas toman decisiones cada vez mÃ¡s complejas:

Impactan mÃºltiples stakeholders

Tienen consecuencias Ã©ticas y reputacionales

Generan efectos sistÃ©micos no lineales

Operan bajo incertidumbre y presiÃ³n temporal

Las herramientas actuales presentan limitaciones claras:

Dashboards: miden resultados, no calidad decisional

ConsultorÃ­a humana: costosa, lenta y no escalable

Chatbots / LLMs: no auditables, no confiables para contextos crÃ­ticos

Existe un vacÃ­o entre pensar y decidir bien.

3. La SoluciÃ³n: Binah-Î£

Binah-Î£ es un motor de evaluaciÃ³n cognitiva que:

Descompone decisiones complejas (principio Binah)

Sintetiza coherencia estructural (principio Î£)

EvalÃºa riesgos Ã©ticos y sistÃ©micos

Produce salidas estrictamente estructuradas

Genera mÃ©tricas longitudinales de calidad decisional

Output tÃ­pico

El sistema no entrega texto libre, sino un informe estructurado, por ejemplo:

Ãndice Binah-Î£ (0â€“1)

Nivel de confianza

Tensiones clave

Riesgos sistÃ©micos

Consecuencias no intencionadas

RecomendaciÃ³n sintÃ©tica

Esto permite comparar decisiones, auditar procesos y mejorar con el tiempo.

4. DiferenciaciÃ³n Clave

No es un chatbot

IA Generativa

Binah-Î£

Produce texto

EvalÃºa decisiones

No auditable

Auditabilidad nativa

Prompt-dependiente

Sistema-dependiente

Resultados efÃ­meros

MÃ©tricas acumulativas

Killer Feature Real

La ventaja competitiva no es el modelo subyacente, sino la infraestructura de control, validaciÃ³n y mÃ©tricas que rodea al razonamiento.

5. Arquitectura TÃ©cnica (Resumen)

Binah-Î£ se construye como un servicio desacoplado y escalable:

API Gateway (FastAPI, async)

Motor de razonamiento estructurado

ValidaciÃ³n estricta por esquema

Logging cognitivo (no textual)

MÃ©tricas agregadas

Persistencia opcional

Esto permite:

Alta concurrencia

Trazabilidad

IntegraciÃ³n con sistemas existentes

Cumplimiento regulatorio

6. Auditabilidad y MÃ©tricas (Ventaja EstratÃ©gica)

Cada anÃ¡lisis genera seÃ±ales estructurales:

Ãndices numÃ©ricos

CategorÃ­as de riesgo

Latencia

Dominio decisional

Estas seÃ±ales permiten:

AuditorÃ­a retrospectiva

Benchmarking interno

DetecciÃ³n temprana de fallos decisionales

Gobierno corporativo basado en datos

Binah-Î£ no registra razonamientos internos, sino resultados cognitivos observables.

7. Casos de Uso Iniciales

EvaluaciÃ³n de polÃ­ticas pÃºblicas

Decisiones ESG y compliance

Fusiones y adquisiciones

Estrategia corporativa

Inversiones de alto impacto

AnÃ¡lisis de riesgos regulatorios

8. Modelo de Negocio (Preliminar)

SaaS por volumen de anÃ¡lisis

Licencias enterprise

API metered usage

Dashboards de auditorÃ­a premium

White-label para instituciones

El valor crece con el uso, no solo con el acceso.

9. Ventaja Defensiva

Vendor-agnostic respecto al modelo LLM

Know-how en diseÃ±o cognitivo

Datos agregados de calidad decisional

Barrera conceptual y tÃ©cnica

El sistema mejora no porque â€œaprendaâ€, sino porque mide.

10. VisiÃ³n

Binah-Î£ aspira a convertirse en:

El estÃ¡ndar de referencia para evaluar la calidad de las decisiones humanas y organizacionales en sistemas complejos.

No reemplaza al decisor.

Eleva el nivel de la decisiÃ³n.

11. Estado Actual

MVP funcional

Arquitectura validada

Endpoint operativo

Casos de estudio en desarrollo

Listo para:

Pilotos

Alianzas estratÃ©gicas

InversiÃ³n semilla / pre-seed

Binah-Î£

Infraestructura cognitiva.
No opiniÃ³n.
No discurso.
DecisiÃ³n medible.







Binah-Î£ desde cero (producto real)

Voy a darte la arquitectura definitiva, sin adornos.

1ï¸âƒ£ VisiÃ³n general
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend    â”‚
â”‚ (UI / API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway (FastAPI)â”‚
â”‚  - Auth              â”‚
â”‚  - Rate limit        â”‚
â”‚  - Validation        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Binah-Î£ Engine       â”‚
â”‚ - Prompt Orchestrationâ”‚
â”‚ - LLM Call           â”‚
â”‚ - JSON enforcement   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validation Layer     â”‚
â”‚ - Pydantic schemas   â”‚
â”‚ - Consistency checks â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Logging      â”‚  â”‚ Metrics Engine â”‚
â”‚ (Structured) â”‚  â”‚ (KPIs)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Storage (Optional)   â”‚
â”‚ - Decisions          â”‚
â”‚ - Aggregates         â”‚Binah-Î£ desde cero (producto real)

Voy a darte la arquitectura definitiva, sin adornos.

1ï¸âƒ£ VisiÃ³n general
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend    â”‚
â”‚ (UI / API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway (FastAPI)â”‚
â”‚  - Auth              â”‚
â”‚  - Rate limit        â”‚
â”‚  - Validation        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Binah-Î£ Engine       â”‚
â”‚ - Prompt Orchestrationâ”‚
â”‚ - LLM Call           â”‚
â”‚ - JSON enforcement   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validation Layer     â”‚
â”‚ - Pydantic schemas   â”‚
â”‚ - Consistency checks â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Logging      â”‚  â”‚ Metrics Engine â”‚
â”‚ (Structured) â”‚  â”‚ (KPIs)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Storage (Optional)   â”‚
â”‚ - Decisions          â”‚
â”‚ - Aggregates         â”‚

















# Binah-Î£ â€” Cognitive Decision Infrastructure

## README.md










### Overview

Binah-Î£ is a **cognitive decision evaluation engine** designed to analyze complex decisions through structured, ethical, and systemic lenses. Unlike generative chat systems, Binah-Î£ produces **auditable, structured outputs** suitable for enterprise, policy, ESG, and compliance use cases.

This repository contains the **complete MVP implementation**: backend API, reasoning engine, schemas, and a demo frontend.

---

## Key Features

* Structured decision evaluation (not text generation)
* Strict JSON output enforced by schema
* Async, non-blocking API
* Audit-ready logging and metrics hooks
* LLM vendor-agnostic architecture
* Frontend demo for immediate validation

---

## Tech Stack

* Python 3.10+
* FastAPI (async)
* Pydantic
* OpenAI SDK (pluggable)
* HTML + Vanilla JS (demo frontend)

---

## Project Structure

```
binah-sigma/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html
â”‚
â””â”€â”€ README.md
```

---

## Backend Setup

### 1. Environment Variables

Create a `.env` file:

```
OPENAI_API_KEY=your_api_key_here
```

### 2. Install Dependencies

```
pip install -r requirements.txt
```

### 3. Run API

```
uvicorn main:app --reload
```

API will be available at:

```
http://localhost:8000
```

Swagger UI:

```
http://localhost:8000/docs
```

---

## Backend Code

### requirements.txt

```
fastapi
uvicorn
pydantic
python-dotenv
openai
```

---

### schemas.py

```python
from pydantic import BaseModel
from typing import List

class BinahSigmaRequest(BaseModel):
    context: str
    decision_question: str
    stakeholders: List[str]
    constraints: List[str]
    time_horizon: str

class BinahSigmaResponse(BaseModel):
    binah_sigma_index: float
    binah_sigma_confidence: float
    decision_coherence: str
    ethical_alignment: str
    systemic_risk: str
    key_tensions: List[str]
    unintended_consequences: List[str]
    binah_recommendation: str
    explanation_summary: str
    analysis_version: str
```

---

### engine.py

```python
import os
import json
from openai import AsyncOpenAI
from schemas import BinahSigmaResponse

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BINAH_SIGMA_SYSTEM = """
You are Binah-Î£, a deep synthesis reasoning engine.
Your role is NOT to chat, speculate, persuade, or generate generic advice.

STRICT RULES:
- Decompose complexity (Binah) and synthesize coherence (Î£).
- Never expose chain-of-thought.
- Output ONLY valid JSON following the Binah-Î£ schema.
"""

BINAH_SIGMA_PROMPT = """
Context: {context}
Decision Question: {decision_question}
Stakeholders: {stakeholders}
Constraints: {constraints}
Time Horizon: {time_horizon}

Apply the Binah-Î£ methodology strictly.
Return ONLY valid JSON.
"""

async def run_binah_sigma(data: dict) -> dict:
    prompt = BINAH_SIGMA_PROMPT.format(**data)

    response = await client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": BINAH_SIGMA_SYSTEM},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        response_format={"type": "json_object"}
    )

    content = response.choices[0].message.content
    parsed = json.loads(content)

    validated = BinahSigmaResponse(**parsed)
    return validated.dict()
```

---

### main.py

```python
from fastapi import FastAPI, HTTPException
from pydantic import ValidationError
from schemas import BinahSigmaRequest, BinahSigmaResponse
from engine import run_binah_sigma

app = FastAPI(title="Binah-Î£ Decision Engine")

@app.post(
    "/binah-sigma/analyze",
    response_model=BinahSigmaResponse,
    summary="Run structured Binah-Î£ decision analysis",
)
async def analyze_decision(payload: BinahSigmaRequest):
    try:
        result = await run_binah_sigma(payload.dict())
        return result
    except ValidationError as e:
        raise HTTPException(
            status_code=502,
            detail="Upstream reasoning engine produced invalid structured output"
        )
    except Exception:
        raise HTTPException(
            status_code=500,
            detail="Internal reasoning engine error"
        )
```

---

## Frontend Demo

### frontend/index.html

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Binah-Î£ Demo</title>
  <style>
    body { font-family: monospace; padding: 40px; }
    textarea, input { width: 100%; margin-bottom: 12px; }
    button { padding: 10px; }
    pre { background: #111; color: #0f0; padding: 20px; }
  </style>
</head>
<body>
  <h1>Binah-Î£ Decision Analysis</h1>

  <input id="context" placeholder="Context" />
  <textarea id="question" placeholder="Decision question"></textarea>
  <textarea id="stakeholders" placeholder="Stakeholders (comma separated)"></textarea>
  <textarea id="constraints" placeholder="Constraints (comma separated)"></textarea>
  <input id="time" placeholder="Time horizon" />

  <button onclick="runAnalysis()">Run Binah-Î£</button>

  <pre id="output"></pre>

<script>
async function runAnalysis() {
  const payload = {
    context: document.getElementById('context').value,
    decision_question: document.getElementById('question').value,
    stakeholders: document.getElementById('stakeholders').value.split(','),
    constraints: document.getElementById('constraints').value.split(','),
    time_horizon: document.getElementById('time').value
  };

  const res = await fetch('http://localhost:8000/binah-sigma/analyze', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(payload)
  });

  const data = await res.json();
  document.getElementById('output').textContent = JSON.stringify(data, null, 2);
}
</script>
</body>
</html>
```

---

## License

Proprietary / Confidential â€” All rights reserved.

---

**Binah-Î£**

Cognitive infrastructure for measurable decisions.
Not chat. Not opinion. Structured judgment.
